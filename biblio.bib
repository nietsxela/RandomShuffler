@misc{Wolfram,
title={Shuffle},
author={Wolfram Mathworld},
url={https://mathworld.wolfram.com/Shuffle.html},
journal={from Wolfram MathWorld}
}

@misc{GS1955,
title = "Theory of shuffling",
author = "Gilbert, E and Shannon, C",
year = {1955},
journal={Technical memorandum, Bell Laboratories},
}

@article{BD92,
author = "Bayer, Dave and Diaconis, Persi",
doi = "10.1214/aoap/1177005705",
fjournal = "Annals of Applied Probability",
journal = "Ann. Appl. Probab.",
month = "05",
number = "2",
pages = "294--313",
publisher = "The Institute of Mathematical Statistics",
title = "Trailing the Dovetail Shuffle to its Lair",
url = "https://doi.org/10.1214/aoap/1177005705",
volume = "2",
year = "1992"
}

@article{MANN95,
  title={How many times should you shuffle a deck of cards},
  author={Mann, Brad},
  journal={Topics in Contemporary Probability and Its Applications},
  volume={15},
  pages={1--33},
  year={1995},
  publisher={CRC Press}
}

@article{TT2000,
 ISSN = {1364-5021},
 URL = {https://doi.org/10.1098/rspa.2000.0625},
 abstract = {A celebrated theorem of Aldous, Bayer and Diaconis asserts that it takes ∼3/2log2 n riffle shuffles to randomize a deck of n cards, asymptotically as n → ∞, and that the randomization occurs abruptly according to a `cut-off phenomenon'. These results depend upon measuring randomness by a quantity known as the total variation distance. If randomness is measured by uncertainty or entropy in the sense of information theory, the behaviour is different. It takes only ∼log2 n shuffles to reduce the information to a proportion arbitrarily close to zero, and ∼3/2 log2 n to reduce it to an arbitrarily small number of bits. At 3/2 log2 n shuffles, ca. 0.0601 bits remain, independently of n.},
 author = {Trefethen, L. N. and  Trefethen, L. M.},
 journal = {Proceedings: Mathematical, Physical and Engineering Sciences},
 number = {2002},
 pages = {2561--2568},
 publisher = {The Royal Society},
 title = {How Many Shuffles to Randomize a Deck of Cards?},
 volume = {456},
 year = {2000}
}